{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import subprocess\n",
    "import os\n",
    "import io\n",
    "import tokenize\n",
    "import ast\n",
    "import json\n",
    "import re\n",
    "import threading\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def remove_comments_and_docstrings(source: str) -> str:\n",
    "    \"\"\"Removes comments and docstrings from Python source code.\"\"\"\n",
    "    io_obj = io.StringIO(source)\n",
    "    output_tokens = []\n",
    "    prev_toktype = tokenize.INDENT\n",
    "    last_lineno = -1\n",
    "    last_col = 0\n",
    "    for tok in tokenize.generate_tokens(io_obj.readline):\n",
    "        token_type, token_string, (start_line, start_col), (end_line, end_col), _ = tok\n",
    "        if start_line > last_lineno:\n",
    "            last_col = 0\n",
    "        # Remove comments\n",
    "        if token_type == tokenize.COMMENT:\n",
    "            continue\n",
    "        # Remove docstrings (multi-line & single-line)\n",
    "        if token_type == tokenize.STRING and prev_toktype in {tokenize.INDENT, tokenize.NEWLINE}:\n",
    "            continue\n",
    "        output_tokens.append((token_type, token_string))\n",
    "        prev_toktype = token_type\n",
    "        last_col = end_col\n",
    "        last_lineno = end_line\n",
    "    # Convert tokens back to source code\n",
    "    new_source = tokenize.untokenize(output_tokens)\n",
    "    # Remove empty lines\n",
    "    return '\\n'.join(line for line in new_source.splitlines() if line.strip())\n",
    "\n",
    "\n",
    "def process_python_file(file_path: str):\n",
    "    \"\"\"Reads a Python file, removes comments/docstrings, and overwrites it.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            stripped_code = remove_comments_and_docstrings(f.read())\n",
    "        # Save back to the original file\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(stripped_code)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def clean_python_files(target_dir):\n",
    "    \"\"\"Find all .py files in the target directory and clean them up.\"\"\"\n",
    "    print(\"Phase 1: Cleaning Python files...\")\n",
    "    py_files = glob.glob(os.path.join(target_dir, '**', '*.py'), recursive=True)\n",
    "\n",
    "    # Process files with a progress bar\n",
    "    with tqdm(total=len(py_files), desc=\"Removing comments & docstrings\", unit=\"file\") as pbar:\n",
    "        for file in py_files:\n",
    "            # Step 1: Remove comments & docstrings\n",
    "            process_python_file(file)\n",
    "            # Step 2: Run autoflake to clean up unused imports/variables\n",
    "            try:\n",
    "                subprocess.run(['autoflake', '--in-place', '--remove-all-unused-imports', '--remove-unused-variables', file],\n",
    "                               check=True, capture_output=True)\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                print(f\"Warning: autoflake failed on {file}: {e}\")\n",
    "            except FileNotFoundError:\n",
    "                print(\"Warning: autoflake not found. Install with 'pip install autoflake' to remove unused imports.\")\n",
    "                break\n",
    "            pbar.update(1)\n",
    "\n",
    "    print(f\"Processed {len(py_files)} Python files.\")\n",
    "    return py_files\n",
    "\n",
    "\n",
    "def extract_definitions(file_path):\n",
    "    \"\"\"Extract defined variables and functions from a Python file.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            code = f.read()\n",
    "        tree = ast.parse(code)\n",
    "        definitions = {}\n",
    "        for node in ast.walk(tree):\n",
    "            if isinstance(node, ast.FunctionDef):\n",
    "                definitions[node.name] = {'type': 'function', 'context': code}\n",
    "            elif isinstance(node, ast.Assign):\n",
    "                for target in node.targets:\n",
    "                    if isinstance(target, ast.Name) and isinstance(target.ctx, ast.Store):\n",
    "                        definitions[target.id] = {'type': 'variable', 'context': code}\n",
    "        return definitions\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting definitions from {file_path}: {e}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "def suggest_better_name(name, def_type, context):\n",
    "    \"\"\"Suggest a snake_case name based on context.\"\"\"\n",
    "    # Simple conversion to snake_case\n",
    "    if name.isupper():  # Likely a constant, keep it\n",
    "        return name\n",
    "\n",
    "    # Convert camelCase/PascalCase to snake_case\n",
    "    s1 = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', name)\n",
    "    snake_case = re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', s1).lower()\n",
    "\n",
    "    # Don't rename if it's already snake_case or starts with underscore\n",
    "    if snake_case == name or name.startswith('_'):\n",
    "        return name\n",
    "\n",
    "    return snake_case\n",
    "\n",
    "\n",
    "def generate_rename_map(directory, map_file):\n",
    "    \"\"\"Generate a map of names to their snake_case equivalents.\"\"\"\n",
    "    print(\"\\nPhase 2: Generating rename map...\")\n",
    "    all_definitions = {}\n",
    "\n",
    "    # Get all Python files\n",
    "    py_files = []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.py'):\n",
    "                py_files.append(os.path.join(root, file))\n",
    "\n",
    "    # Process files with a progress bar\n",
    "    with tqdm(total=len(py_files), desc=\"Extracting definitions\", unit=\"file\") as pbar:\n",
    "        for file_path in py_files:\n",
    "            defs = extract_definitions(file_path)\n",
    "            all_definitions[file_path] = defs\n",
    "            pbar.update(1)\n",
    "\n",
    "    rename_map = {}\n",
    "    for file_path, defs in all_definitions.items():\n",
    "        for name, info in defs.items():\n",
    "            if name not in rename_map:  # Only suggest once per unique name\n",
    "                new_name = suggest_better_name(name, info['type'], info['context'])\n",
    "                if new_name != name and not new_name.startswith('_'):  # Avoid private names\n",
    "                    rename_map[name] = new_name\n",
    "\n",
    "    # Save to JSON\n",
    "    with open(map_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(rename_map, f, indent=4)\n",
    "\n",
    "    print(f\"Generated rename map with {len(rename_map)} entries, saved to {map_file}\")\n",
    "    return rename_map\n",
    "\n",
    "\n",
    "def replace_in_file(file_path, rename_map):\n",
    "    \"\"\"Replace occurrences in a file using regex with word boundaries.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        original_content = content\n",
    "\n",
    "        # Create a regex pattern that matches any of the keys with word boundaries\n",
    "        pattern = r'\\b(?:' + '|'.join(re.escape(key) for key in rename_map.keys()) + r')\\b'\n",
    "\n",
    "        def replacer(match):\n",
    "            return rename_map[match.group(0)]\n",
    "\n",
    "        new_content = re.sub(pattern, replacer, content)\n",
    "\n",
    "        # Only write if content changed\n",
    "        if new_content != original_content:\n",
    "            with open(file_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(new_content)\n",
    "            return True\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def process_directory(directory, rename_map):\n",
    "    \"\"\"Process all Python files in directory using multiple threads.\"\"\"\n",
    "    print(\"\\nPhase 3: Applying renames to files...\")\n",
    "    py_files = [os.path.join(root, file)\n",
    "                for root, _, files in os.walk(directory)\n",
    "                for file in files if file.endswith('.py')]\n",
    "\n",
    "    if not py_files:\n",
    "        print(\"No Python files found in the directory.\")\n",
    "        return\n",
    "\n",
    "    results = [False] * len(py_files)\n",
    "\n",
    "    # Function to be executed by each thread\n",
    "    def process_file(index, file_path):\n",
    "        results[index] = replace_in_file(file_path, rename_map)\n",
    "\n",
    "    # Create and start threads with progress bar\n",
    "    with tqdm(total=len(py_files), desc=\"Replacing variables/functions\", unit=\"file\") as pbar:\n",
    "        with ThreadPoolExecutor(max_workers=os.cpu_count() or 4) as executor:\n",
    "            # Submit tasks and keep track of futures\n",
    "            futures = []\n",
    "            for i, file_path in enumerate(py_files):\n",
    "                future = executor.submit(process_file, i, file_path)\n",
    "                future.add_done_callback(lambda p: pbar.update(1))\n",
    "                futures.append(future)\n",
    "\n",
    "            # Wait for all tasks to complete\n",
    "            for future in futures:\n",
    "                try:\n",
    "                    future.result()\n",
    "                except Exception as e:\n",
    "                    print(f\"Thread error: {e}\")\n",
    "\n",
    "    changed_files = sum(results)\n",
    "    print(f\"Completed! Changed {changed_files} of {len(py_files)} files.\")\n",
    "    return changed_files\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"=== Python Code Cleanup and Rename Tool ===\")\n",
    "    target_dir = input(\"Enter your project directory: \")\n",
    "\n",
    "    if not os.path.isdir(target_dir):\n",
    "        print(f\"Error: '{target_dir}' is not a valid directory.\")\n",
    "        return\n",
    "\n",
    "    # Create a backup first\n",
    "    backup_option = input(\"Do you want to create a backup before proceeding? (y/n): \").lower()\n",
    "    if backup_option == 'y':\n",
    "        import shutil\n",
    "        from datetime import datetime\n",
    "\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        backup_dir = f\"{target_dir}_backup_{timestamp}\"\n",
    "        print(f\"Creating backup to {backup_dir}...\")\n",
    "        shutil.copytree(target_dir, backup_dir)\n",
    "        print(\"Backup created!\")\n",
    "\n",
    "    # Clean Python files (remove comments, docstrings, unused imports)\n",
    "    clean_python_files(target_dir)\n",
    "\n",
    "    # Generate rename map\n",
    "    map_file = os.path.join(os.path.dirname(target_dir), \"rename_map.json\")\n",
    "    rename_map = generate_rename_map(target_dir, map_file)\n",
    "\n",
    "    # Preview changes\n",
    "    print(\"\\nPreview of renames:\")\n",
    "    for i, (old, new) in enumerate(list(rename_map.items())[:10], 1):\n",
    "        print(f\"{i}. {old} -> {new}\")\n",
    "\n",
    "    if len(rename_map) > 10:\n",
    "        print(f\"... and {len(rename_map) - 10} more renames\")\n",
    "\n",
    "    # Ask to proceed\n",
    "    proceed = input(\"\\nDo you want to proceed with these renames? (y/n): \").lower()\n",
    "    if proceed != 'y':\n",
    "        print(\"Rename operation cancelled.\")\n",
    "        return\n",
    "\n",
    "    # Apply renames\n",
    "    process_directory(target_dir, rename_map)\n",
    "    print(\"\\nAll operations completed!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
