{
	"cells": [
		{
			"cell_type": "code",
			"execution_count": 8,
			"metadata": {},
			"outputs": [
				{
					"name": "stderr",
					"output_type": "stream",
					"text": [
						"Refactoring:   0%|          | 0/50 [00:00<?, ?file/s]"
					]
				},
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"File exceeds token limit: C:\\Users\\harold.noble\\Desktop\\RIC\\app\\frontend\\src\\lib\\apis\\index.ts\n"
					]
				},
				{
					"name": "stderr",
					"output_type": "stream",
					"text": [
						"Refactoring:  62%|██████▏   | 31/50 [07:18<03:40, 11.63s/file]"
					]
				},
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"LLM error with C:\\Users\\harold.noble\\Desktop\\RIC\\app\\frontend\\src\\lib\\components\\admin\\Evaluations\\Leaderboard.svelte: API failed after 3 retries: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01j1qez3f7fj98shsdn8gf3qsm` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 102416, Requested 3379. Please try again in 1h23m27.285999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
					]
				},
				{
					"name": "stderr",
					"output_type": "stream",
					"text": [
						"Refactoring:  64%|██████▍   | 32/50 [07:22<02:47,  9.32s/file]"
					]
				},
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"LLM error with C:\\Users\\harold.noble\\Desktop\\RIC\\app\\frontend\\src\\lib\\components\\admin\\Functions\\FunctionEditor.svelte: API failed after 3 retries: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01j1qez3f7fj98shsdn8gf3qsm` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 102411, Requested 3903. Please try again in 1h30m56.079s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
					]
				},
				{
					"name": "stderr",
					"output_type": "stream",
					"text": [
						"Refactoring:  66%|██████▌   | 33/50 [07:31<03:52, 13.70s/file]\n"
					]
				},
				{
					"ename": "KeyboardInterrupt",
					"evalue": "",
					"output_type": "error",
					"traceback": [
						"\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
						"\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
						"Cell \u001b[1;32mIn[8], line 97\u001b[0m, in \u001b[0;36mfetch_llm_response\u001b[1;34m(prompt, system_prompt, model, temperature, top_p, retries)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 97\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTIMEOUT_SECONDS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mstrip()\n",
						"File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\groq\\resources\\chat\\completions.py:322\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, n, parallel_tool_calls, presence_penalty, reasoning_format, response_format, seed, service_tier, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;124;03mCreates a model response for the given chat conversation.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;124;03m  timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 322\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/openai/v1/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    339\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
						"File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\groq\\_base_client.py:1266\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1263\u001b[0m opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1264\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1265\u001b[0m )\n\u001b[1;32m-> 1266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
						"File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\groq\\_base_client.py:958\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    956\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 958\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
						"File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\groq\\_base_client.py:1061\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1060\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1061\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1064\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1065\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1069\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1070\u001b[0m )\n",
						"\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01j1qez3f7fj98shsdn8gf3qsm` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 102403, Requested 5566. Please try again in 1h54m45.318s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
						"\nDuring handling of the above exception, another exception occurred:\n",
						"\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
						"Cell \u001b[1;32mIn[8], line 326\u001b[0m\n\u001b[0;32m    322\u001b[0m             pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 326\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
						"Cell \u001b[1;32mIn[8], line 317\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(batch), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRefactoring\u001b[39m\u001b[38;5;124m\"\u001b[39m, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m file_path \u001b[38;5;129;01min\u001b[39;00m batch:\n\u001b[1;32m--> 317\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mprocess_single_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproblematic_files\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    318\u001b[0m             processed_files\u001b[38;5;241m.\u001b[39madd(file_path)\n\u001b[0;32m    319\u001b[0m             save_processed_files(PROCESSED_FILES_TRACKER, processed_files)\n",
						"Cell \u001b[1;32mIn[8], line 249\u001b[0m, in \u001b[0;36mprocess_single_file\u001b[1;34m(file_path, problematic_files)\u001b[0m\n\u001b[0;32m    246\u001b[0m     tqdm\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile exceeds token limit: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 249\u001b[0m refactored_content \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_llm_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_valid_code(file_path, refactored_content):\n\u001b[0;32m    252\u001b[0m     problematic_files\u001b[38;5;241m.\u001b[39madd(file_path)\n",
						"Cell \u001b[1;32mIn[8], line 112\u001b[0m, in \u001b[0;36mfetch_llm_response\u001b[1;34m(prompt, system_prompt, model, temperature, top_p, retries)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attempt \u001b[38;5;241m==\u001b[39m retries \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI failed after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mretries\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m retries: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 112\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mattempt\u001b[49m\u001b[43m)\u001b[49m\n",
						"\u001b[1;31mKeyboardInterrupt\u001b[0m: "
					]
				}
			],
			"source": [
				"#!/usr/bin/env python3\n",
				"\"\"\"\n",
				"Script to refactor Python, Svelte, and TypeScript files using LLM streaming.\n",
				"Processes files, tracks progress, and overwrites originals with refactored code.\n",
				"Skips specified subfolders and logs problematic files to 'problematic_files.txt'.\n",
				"\"\"\"\n",
				"\n",
				"import os\n",
				"import re\n",
				"import time\n",
				"from typing import List, Set\n",
				"import ast\n",
				"import chardet\n",
				"from groq import Groq\n",
				"from tqdm import tqdm\n",
				"\n",
				"GROQ_API_KEY = \"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\"\n",
				"DEFAULT_DIRECTORY = r\"C:\\Users\\harold.noble\\Desktop\\RIC\\app\\frontend\\src\"\n",
				"SKIP_FOLDERS = frozenset({\".github\", \"code_helper\", \"ollama-0\"})\n",
				"PROCESSED_FILES_TRACKER = \"processed_files.txt\"\n",
				"PROBLEMATIC_FILES_LOG = \"problematic_files.txt\"\n",
				"FILES_PER_RUN = 50\n",
				"LLM_MODEL = \"llama-3.3-70b-versatile\"\n",
				"LLM_TEMPERATURE = 0.5\n",
				"LLM_TOP_P = 0.9\n",
				"TIMEOUT_SECONDS = 180\n",
				"MAX_RETRIES = 3\n",
				"MAX_TOKENS = 6000\n",
				"\n",
				"SYSTEM_PROMPT = \"\"\"\n",
				"You are an expert developer specializing in code refactoring, created to assist with optimizing code scripts. Your role is to refactor entire scripts while preserving their original functionality, function names, and file type (Python, Svelte, or TypeScript).\n",
				"\n",
				"IMPORTANT: Your response must contain ONLY the refactored code with no explanations, comments about changes, or formatting markers. Do not include markdown code blocks, explanations, or anything else that is not part of the actual code. Maintain the original file type (Python, Svelte, or TypeScript).\n",
				"\"\"\"\n",
				"\n",
				"REFACTOR_PROMPT = \"\"\"\n",
				"Refactor the {file_type} code I provide according to the following guidelines:\n",
				"1. Remove Components: Delete all code and derivatives related to: Gemini, ComfyUI, Tika, document intelligence, checkForVersionUpdates, playground, WebhookUrl, LDAP, OAuth, enable_community_sharing, ShareChat, ENABLE_CHANNELS, channels, channel_id, playground, Deepgram, Webhook, Proxy, Youtube Proxy, nonLocalVoices, haptic, mobile, and all i18n-related code and references.\n",
				"2. Optimize Performance: Simplify logic flows and remove redundancies and inefficiencies. Streamline operations without sacrificing readability.\n",
				"3. Clean Codebase: Eliminate unused imports and dead code.\n",
				"5. Strengthen Error Handling: Use specific exceptions (e.g., ValueError, IOError) where applicable. Provide clear and actionable error messages.\n",
				"6. Enhance Documentation: Add docstrings for modules, functions, and classes in Python, or JSDoc-style comments for TypeScript/Svelte. Keep inline comments for notes that cannot be included in documentation.\n",
				"Constraints: Preserve existing function names and file type (Python, Svelte, or TypeScript). Return only the refactored code, without explanations or summaries. Include documentation appropriate to the file type. Refactor solely based on the code provided. Do not change exported functions or variable names. The current date is March 07, 2025. Process only the single script I provide.\n",
				"\n",
				"Code:\n",
				"{code_content}\n",
				"\"\"\"\n",
				"\n",
				"\n",
				"def get_file_type(file_path: str) -> str:\n",
				"    \"\"\"Determine the file type based on extension.\"\"\"\n",
				"    if file_path.endswith(\".py\"):\n",
				"        return \"Python\"\n",
				"    elif file_path.endswith(\".svelte\"):\n",
				"        return \"Svelte\"\n",
				"    elif file_path.endswith((\".ts\", \".tsx\")):\n",
				"        return \"TypeScript\"\n",
				"    elif file_path.endswith(\".js\"):\n",
				"        return \"JavaScript\"\n",
				"    return \"Unknown\"\n",
				"\n",
				"\n",
				"def fetch_llm_response(\n",
				"    prompt: str,\n",
				"    system_prompt: str = SYSTEM_PROMPT,\n",
				"    model: str = LLM_MODEL,\n",
				"    temperature: float = LLM_TEMPERATURE,\n",
				"    top_p: float = LLM_TOP_P,\n",
				"    retries: int = MAX_RETRIES,\n",
				") -> str:\n",
				"    \"\"\"\n",
				"    Fetch refactored code from the Groq API.\n",
				"\n",
				"    Args:\n",
				"        prompt: Prompt with code to refactor.\n",
				"        system_prompt: Instructions for the LLM.\n",
				"        model: LLM model to use.\n",
				"        temperature: Sampling temperature.\n",
				"        top_p: Top-p sampling parameter.\n",
				"        retries: Number of retry attempts.\n",
				"\n",
				"    Returns:\n",
				"        Refactored code string.\n",
				"\n",
				"    Raises:\n",
				"        ValueError: If prompt or API key is invalid.\n",
				"        RuntimeError: If API fails after retries.\n",
				"    \"\"\"\n",
				"    if not prompt or not isinstance(prompt, str):\n",
				"        raise ValueError(\"Prompt must be a non-empty string\")\n",
				"    if not GROQ_API_KEY:\n",
				"        raise ValueError(\"GROQ_API_KEY must be set\")\n",
				"\n",
				"    client = Groq(api_key=GROQ_API_KEY)\n",
				"    for attempt in range(retries):\n",
				"        try:\n",
				"            response = client.chat.completions.create(\n",
				"                messages=[\n",
				"                    {\"role\": \"system\", \"content\": system_prompt},\n",
				"                    {\"role\": \"user\", \"content\": prompt},\n",
				"                ],\n",
				"                model=model,\n",
				"                temperature=temperature,\n",
				"                top_p=top_p,\n",
				"                stream=False,\n",
				"                timeout=TIMEOUT_SECONDS,\n",
				"            )\n",
				"            return response.choices[0].message.content.strip()\n",
				"        except Exception as e:\n",
				"            if attempt == retries - 1:\n",
				"                raise RuntimeError(f\"API failed after {retries} retries: {str(e)}\")\n",
				"            time.sleep(2 ** attempt)\n",
				"\n",
				"\n",
				"def load_processed_files(tracker_file: str) -> Set[str]:\n",
				"    \"\"\"\n",
				"    Load processed file paths from tracker file.\n",
				"\n",
				"    Args:\n",
				"        tracker_file: Path to tracker file.\n",
				"\n",
				"    Returns:\n",
				"        Set of processed file paths.\n",
				"    \"\"\"\n",
				"    processed = set()\n",
				"    try:\n",
				"        if not os.path.exists(tracker_file):\n",
				"            with open(tracker_file, \"w\", encoding=\"utf-8\") as f:\n",
				"                f.write(\"# Processed Files\\n# Tracks refactored files\\n\\n\")\n",
				"        else:\n",
				"            with open(tracker_file, \"r\", encoding=\"utf-8\") as f:\n",
				"                processed.update(line.strip() for line in f if line.strip() and not line.startswith(\"#\"))\n",
				"    except IOError as e:\n",
				"        tqdm.write(f\"Failed to load {tracker_file}: {str(e)}\")\n",
				"    return processed\n",
				"\n",
				"\n",
				"def save_processed_files(tracker_file: str, processed: Set[str]) -> None:\n",
				"    \"\"\"\n",
				"    Save processed file paths to tracker file.\n",
				"\n",
				"    Args:\n",
				"        tracker_file: Path to tracker file.\n",
				"        processed: Set of processed file paths.\n",
				"    \"\"\"\n",
				"    try:\n",
				"        with open(tracker_file, \"w\", encoding=\"utf-8\") as f:\n",
				"            f.write(\"# Processed Files\\n# Tracks refactored files\\n\\n\")\n",
				"            f.writelines(f\"{path}\\n\" for path in sorted(processed))\n",
				"    except IOError as e:\n",
				"        tqdm.write(f\"Failed to save {tracker_file}: {str(e)}\")\n",
				"\n",
				"\n",
				"def load_problematic_files(log_file: str) -> Set[str]:\n",
				"    \"\"\"\n",
				"    Load problematic file paths from log file.\n",
				"\n",
				"    Args:\n",
				"        log_file: Path to problematic files log.\n",
				"\n",
				"    Returns:\n",
				"        Set of problematic file paths.\n",
				"    \"\"\"\n",
				"    problematic = set()\n",
				"    try:\n",
				"        if not os.path.exists(log_file):\n",
				"            with open(log_file, \"w\", encoding=\"utf-8\") as f:\n",
				"                f.write(\"# Problematic Files\\n# Tracks files that failed refactoring\\n\\n\")\n",
				"        else:\n",
				"            with open(log_file, \"r\", encoding=\"utf-8\") as f:\n",
				"                problematic.update(line.strip() for line in f if line.strip() and not line.startswith(\"#\"))\n",
				"    except IOError as e:\n",
				"        tqdm.write(f\"Failed to load {log_file}: {str(e)}\")\n",
				"    return problematic\n",
				"\n",
				"\n",
				"def save_problematic_files(log_file: str, problematic: Set[str]) -> None:\n",
				"    \"\"\"\n",
				"    Save problematic file paths to log file.\n",
				"\n",
				"    Args:\n",
				"        log_file: Path to problematic files log.\n",
				"        problematic: Set of problematic file paths.\n",
				"    \"\"\"\n",
				"    try:\n",
				"        with open(log_file, \"w\", encoding=\"utf-8\") as f:\n",
				"            f.write(\"# Problematic Files\\n# Tracks files that failed refactoring\\n\\n\")\n",
				"            f.writelines(f\"{path}\\n\" for path in sorted(problematic))\n",
				"    except IOError as e:\n",
				"        tqdm.write(f\"Failed to save {log_file}: {str(e)}\")\n",
				"\n",
				"\n",
				"def is_valid_code(file_path: str, code: str) -> bool:\n",
				"    \"\"\"\n",
				"    Validate code syntax by file type.\n",
				"\n",
				"    Args:\n",
				"        file_path: Path to the file.\n",
				"        code: Code content to validate.\n",
				"\n",
				"    Returns:\n",
				"        True if syntax is valid, False otherwise.\n",
				"    \"\"\"\n",
				"    if not code.strip():\n",
				"        return False\n",
				"    if file_path.endswith(\".py\"):\n",
				"        try:\n",
				"            ast.parse(code)\n",
				"            return True\n",
				"        except SyntaxError:\n",
				"            return False\n",
				"    # For Svelte/TS/JS, just check if it's non-empty (basic validation)\n",
				"    return True\n",
				"\n",
				"\n",
				"def process_single_file(file_path: str, problematic_files: Set[str]) -> bool:\n",
				"    \"\"\"\n",
				"    Refactor a single file and update it if successful.\n",
				"\n",
				"    Args:\n",
				"        file_path: Path to file to refactor.\n",
				"        problematic_files: Set of files that failed processing.\n",
				"\n",
				"    Returns:\n",
				"        True if refactored and saved, False otherwise.\n",
				"    \"\"\"\n",
				"    try:\n",
				"        with open(file_path, \"rb\") as f:\n",
				"            raw_content = f.read()\n",
				"            detected = chardet.detect(raw_content)\n",
				"            encoding = detected[\"encoding\"] or \"latin1\"\n",
				"        with open(file_path, \"r\", encoding=encoding) as f:\n",
				"            original_content = f.read()\n",
				"\n",
				"        file_type = get_file_type(file_path)\n",
				"        if file_type == \"Unknown\":\n",
				"            problematic_files.add(file_path)\n",
				"            tqdm.write(f\"Unknown file type: {file_path}\")\n",
				"            return False\n",
				"\n",
				"        prompt = REFACTOR_PROMPT.format(file_type=file_type, code_content=original_content)\n",
				"\n",
				"        # Check token limit before sending to LLM\n",
				"        if len(prompt) > MAX_TOKENS * 4:\n",
				"            problematic_files.add(file_path)\n",
				"            tqdm.write(f\"File exceeds token limit: {file_path}\")\n",
				"            return False\n",
				"\n",
				"        refactored_content = fetch_llm_response(prompt)\n",
				"\n",
				"        if not is_valid_code(file_path, refactored_content):\n",
				"            problematic_files.add(file_path)\n",
				"            tqdm.write(f\"Invalid refactored code for {file_path}\")\n",
				"            return False\n",
				"\n",
				"        if refactored_content.strip() == original_content.strip():\n",
				"            return False\n",
				"\n",
				"        with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
				"            f.write(refactored_content.rstrip() + \"\\n\")\n",
				"        return True\n",
				"\n",
				"    except IOError as e:\n",
				"        tqdm.write(f\"IO error with {file_path}: {str(e)}\")\n",
				"        problematic_files.add(file_path)\n",
				"        return False\n",
				"    except RuntimeError as e:\n",
				"        tqdm.write(f\"LLM error with {file_path}: {str(e)}\")\n",
				"        problematic_files.add(file_path)\n",
				"        return False\n",
				"\n",
				"\n",
				"def get_files_to_process(directory: str) -> List[str]:\n",
				"    \"\"\"\n",
				"    Retrieve list of files to process from directory.\n",
				"\n",
				"    Args:\n",
				"        directory: Root directory to scan.\n",
				"\n",
				"    Returns:\n",
				"        List of file paths.\n",
				"    \"\"\"\n",
				"    extensions = (\".py\", \".svelte\", \".ts\", \".tsx\", \".js\")\n",
				"    return [\n",
				"        os.path.join(root, file)\n",
				"        for root, _, files in os.walk(directory)\n",
				"        if not any(skip in root for skip in SKIP_FOLDERS)\n",
				"        for file in files\n",
				"        if file.endswith(extensions)\n",
				"    ]\n",
				"\n",
				"\n",
				"def main() -> None:\n",
				"    \"\"\"\n",
				"    Orchestrate file refactoring with progress tracking.\n",
				"    \"\"\"\n",
				"    if not os.path.isdir(DEFAULT_DIRECTORY):\n",
				"        print(f\"Directory not found: {DEFAULT_DIRECTORY}\")\n",
				"        return\n",
				"\n",
				"    processed_files = load_processed_files(PROCESSED_FILES_TRACKER)\n",
				"    problematic_files = load_problematic_files(PROBLEMATIC_FILES_LOG)\n",
				"    all_files = get_files_to_process(DEFAULT_DIRECTORY)\n",
				"\n",
				"    if not all_files:\n",
				"        print(f\"No files found in {DEFAULT_DIRECTORY}\")\n",
				"        return\n",
				"\n",
				"    files_to_process = [f for f in all_files if f not in processed_files]\n",
				"    if not files_to_process:\n",
				"        print(\"All files processed\")\n",
				"        return\n",
				"\n",
				"    batch = files_to_process[:FILES_PER_RUN]\n",
				"    with tqdm(total=len(batch), desc=\"Refactoring\", unit=\"file\") as pbar:\n",
				"        for file_path in batch:\n",
				"            if process_single_file(file_path, problematic_files):\n",
				"                processed_files.add(file_path)\n",
				"                save_processed_files(PROCESSED_FILES_TRACKER, processed_files)\n",
				"            if file_path in problematic_files:\n",
				"                save_problematic_files(PROBLEMATIC_FILES_LOG, problematic_files)\n",
				"            pbar.update(1)\n",
				"\n",
				"\n",
				"if __name__ == \"__main__\":\n",
				"    main()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": []
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "Python 3",
			"language": "python",
			"name": "python3"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "python",
			"nbconvert_exporter": "python",
			"pygments_lexer": "ipython3",
			"version": "3.12.5"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 2
}
