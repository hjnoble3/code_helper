{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import aiofiles\n",
    "import logging\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Tuple, Optional\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.FileHandler(\"refactoring.log\"), logging.StreamHandler()]\n",
    ")\n",
    "logger = logging.getLogger(\"refactoring\")\n",
    "\n",
    "# Cost definitions\n",
    "INPUT_COST_PER_TOKEN: float = 0.000002  # $2.00 / 1M prompt tokens\n",
    "OUTPUT_COST_PER_TOKEN: float = 0.00001  # $10.00 / 1M completion tokens\n",
    "\n",
    "# Configuration\n",
    "CONFIG: Dict[str, Any] = {\n",
    "    \"base_url\": \"https://api.x.ai/v1\",\n",
    "    \"api_key\": \"xai-Lggu94vl22xIj5ThXFVu9nxbXjqYOqbTtLlxnibCypTkA5F8N4SvT0SDAYKIK8EkQCuVHv3tbfOPGiwt\",\n",
    "    \"progress_file\": \"refactoring_progress.json\",\n",
    "    \"failed_file\": \"refactoring_failed.json\",\n",
    "    \"source_directories\": [r\"C:\\Users\\harold.noble\\Desktop\\RIC\\app\\frontend\"],\n",
    "    \"skip_directories\": [\n",
    "        r\"C:\\Users\\harold.noble\\Desktop\\RIC\\app\\frontend\\src\\lib\\i18n\",\n",
    "        r\"C:\\Users\\harold.noble\\Desktop\\RIC\\app\\frontend\\src\\lib\\components\\channel\",\n",
    "        r\"C:\\Users\\harold.noble\\Desktop\\RIC\\app\\frontend\\src\\lib\\components\\playground\",\n",
    "        r\"C:\\Users\\harold.noble\\Desktop\\RIC\\app\\frontend\\src\\lib\\components\\icons\"\n",
    "    ],\n",
    "    \"model\": \"grok-2-latest\",\n",
    "    \"max_context_tokens\": 131072,\n",
    "    \"request_delay\": 1.0,\n",
    "    \"max_retries\": 3,\n",
    "    \"retry_delay\": 5,\n",
    "    \"timeout\": 120,\n",
    "    \"cost_budget\": 3.0,\n",
    "    \"file_extensions\": [\".py\", \".ts\", \".js\", \".svelte\"],\n",
    "    \"prompt_template\": \"\"\"Refactor the provided code according to these guidelines and return only the modified code:\n",
    "\n",
    "- Remove all code related to: Tika, document_intelligence, check_for_version_updates, playground, webhook_url, ldap, oauth, enable_community_sharing, share_chat, enable_channels, channels, channel_id, deepgram, webhook, proxy, youtube_proxy, non_local_voices, haptic, mobile, i18n\n",
    "- Organize imports: standard library first, then third-party, then local; use explicit imports (no wildcards); remove unused imports\n",
    "- Add TypeScript types where applicable\n",
    "- Add documentation:\n",
    "  * Single-line JSDoc comments (/** Comment */) for simple JavaScript/TypeScript functions or sections\n",
    "  * Multi-line JSDoc (/** ... */) for JavaScript/TypeScript/Svelte functions with params, returns, etc.\n",
    "  * Single-line docstrings ('Comment') for simple Python functions or sections\n",
    "  * Multi-line docstrings (''' ... ''') for Python modules/classes/functions with params, returns, exceptions\n",
    "  * HTML comments for component sections\n",
    "- Error handling: add try/catch for async ops, use specific exceptions, log errors, add fallbacks\n",
    "- UI components: add semantic HTML comments, consistent class naming, maintain functionality\n",
    "- Code quality: remove dead code/redundancies, use clear variable names, simplify expressions, consistent formatting\n",
    "- Requirements:\n",
    "  * Preserve functionality and original file type\n",
    "  * Keep exported function names and public API\n",
    "  * Replace i18n references with direct text (e.g., $i18n.t('text') -> 'text')\n",
    "\n",
    "Input code:\n",
    "{content}\n",
    "\n",
    "Output only the refactored code without any explanations or additional text.\"\"\",\n",
    "    \"auto_commit\": True,\n",
    "    \"auto_commit_interval\": 4,\n",
    "    \"requests_per_minute\": 60,\n",
    "    \"git_root_directory\": r\"C:\\Users\\harold.noble\\Desktop\\RIC\",\n",
    "    \"max_input_tokens\": 120000\n",
    "}\n",
    "\n",
    "\n",
    "def estimate_tokens(text: str) -> int:\n",
    "    \"\"\"Estimate token count (1 token â‰ˆ 4 characters).\"\"\"\n",
    "    return len(text) // 4 + 1\n",
    "\n",
    "\n",
    "async def refactor_code(session: aiohttp.ClientSession, file_path: str, prompt_template: str) -> Tuple[str, Dict[str, Any]]:\n",
    "    \"\"\"Refactor a single file using the AI model.\"\"\"\n",
    "    try:\n",
    "        async with aiofiles.open(file_path, \"r\", encoding=\"utf-8\", errors=\"replace\") as file:\n",
    "            code_content: str = await file.read()\n",
    "\n",
    "        input_tokens: int = estimate_tokens(code_content)\n",
    "        prompt_base_tokens: int = estimate_tokens(prompt_template.format(content=\"\"))\n",
    "        total_input_tokens: int = input_tokens + prompt_base_tokens\n",
    "\n",
    "        if total_input_tokens > CONFIG[\"max_input_tokens\"]:\n",
    "            logger.error(f\"File {file_path} exceeds input limit: {total_input_tokens} > {CONFIG['max_input_tokens']}\")\n",
    "            return \"\", {}\n",
    "\n",
    "        if total_input_tokens >= CONFIG[\"max_context_tokens\"]:\n",
    "            logger.error(f\"File {file_path} too large: {total_input_tokens} tokens >= {CONFIG['max_context_tokens']}\")\n",
    "            return \"\", {}\n",
    "\n",
    "        formatted_prompt: str = prompt_template.format(content=code_content)\n",
    "        max_output_tokens: int = CONFIG[\"max_context_tokens\"] - total_input_tokens - 1000\n",
    "\n",
    "        if max_output_tokens < 1000:\n",
    "            logger.error(f\"Insufficient output token budget for {file_path}: {max_output_tokens}\")\n",
    "            return \"\", {}\n",
    "\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {CONFIG['api_key']}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "\n",
    "        payload = {\n",
    "            \"model\": CONFIG[\"model\"],\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": formatted_prompt}],\n",
    "            \"temperature\": 0.7,\n",
    "            \"max_tokens\": max_output_tokens\n",
    "        }\n",
    "\n",
    "        for attempt in range(CONFIG[\"max_retries\"] + 1):\n",
    "            try:\n",
    "                await asyncio.sleep(60 / CONFIG[\"requests_per_minute\"])\n",
    "                logger.info(f\"Processing {file_path} (attempt {attempt + 1})\")\n",
    "\n",
    "                async with session.post(\n",
    "                    f\"{CONFIG['base_url']}/chat/completions\",\n",
    "                    json=payload,\n",
    "                    headers=headers,\n",
    "                    timeout=aiohttp.ClientTimeout(total=CONFIG[\"timeout\"])\n",
    "                ) as response:\n",
    "                    if response.status != 200:\n",
    "                        error_text = await response.text()\n",
    "                        logger.error(f\"API error {response.status} for {file_path}: {error_text[:200]}\")\n",
    "                        if response.status in (500, 502, 503, 520) and attempt < CONFIG[\"max_retries\"]:\n",
    "                            delay = CONFIG[\"retry_delay\"] * (2 ** attempt)\n",
    "                            await asyncio.sleep(delay)\n",
    "                            continue\n",
    "                        return \"\", {}\n",
    "\n",
    "                    result: Dict[str, Any] = await response.json()\n",
    "                    if \"choices\" not in result or not result[\"choices\"]:\n",
    "                        logger.error(f\"Invalid API response for {file_path}: {result}\")\n",
    "                        return \"\", {}\n",
    "\n",
    "                    return result[\"choices\"][0][\"message\"][\"content\"], result.get(\"usage\", {})\n",
    "\n",
    "            except asyncio.TimeoutError:\n",
    "                logger.warning(f\"Timeout for {file_path} (attempt {attempt + 1})\")\n",
    "                if attempt < CONFIG[\"max_retries\"]:\n",
    "                    await asyncio.sleep(CONFIG[\"retry_delay\"] * (2 ** attempt))\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error for {file_path} (attempt {attempt + 1}): {e}\")\n",
    "                if attempt < CONFIG[\"max_retries\"]:\n",
    "                    await asyncio.sleep(CONFIG[\"retry_delay\"] * (2 ** attempt))\n",
    "                else:\n",
    "                    return \"\", {}\n",
    "\n",
    "        return \"\", {}\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"File access error {file_path}: {e}\")\n",
    "        return \"\", {}\n",
    "\n",
    "\n",
    "async def commit_files(files: List[str], git_root: str) -> None:\n",
    "    \"\"\"Commit refactored files to git.\"\"\"\n",
    "    if not CONFIG[\"auto_commit\"] or not files:\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        os.chdir(git_root)\n",
    "        subprocess.run([\"git\", \"add\"] + [os.path.relpath(f, git_root) for f in files], check=True, capture_output=True, text=True)\n",
    "        subprocess.run([\"git\", \"commit\", \"-m\", f\"Refactor {len(files)} files using AI\"], check=True, capture_output=True, text=True)\n",
    "        logger.info(f\"Committed {len(files)} files\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        logger.error(f\"Git commit failed: {e.stderr}\")\n",
    "\n",
    "\n",
    "def scan_directories() -> List[str]:\n",
    "    \"\"\"Scan directories for files to refactor.\"\"\"\n",
    "    file_paths: List[str] = []\n",
    "    skip_dirs: List[Path] = [Path(d).resolve() for d in CONFIG[\"skip_directories\"]]\n",
    "\n",
    "    for directory in CONFIG[\"source_directories\"]:\n",
    "        dir_path = Path(directory).resolve()\n",
    "        if not dir_path.is_dir():\n",
    "            logger.warning(f\"Invalid directory: {directory}\")\n",
    "            continue\n",
    "\n",
    "        if any(dir_path.is_relative_to(skip) or dir_path == skip for skip in skip_dirs):\n",
    "            continue\n",
    "\n",
    "        for ext in CONFIG[\"file_extensions\"]:\n",
    "            for file_path in dir_path.glob(f\"**/*{ext}\"):\n",
    "                if not any(file_path.is_relative_to(skip) or file_path.parent == skip for skip in skip_dirs):\n",
    "                    file_paths.append(str(file_path))\n",
    "\n",
    "    return file_paths\n",
    "\n",
    "\n",
    "async def load_progress_data() -> Tuple[Dict[str, Any], Dict[str, Any]]:\n",
    "    \"\"\"Load progress and failed files data.\"\"\"\n",
    "    progress_data: Dict[str, Any] = {\"processed_files\": [], \"total_cost\": 0.0}\n",
    "    failed_data: Dict[str, Any] = {\"failed_files\": {}}\n",
    "\n",
    "    for file, data in [(CONFIG[\"progress_file\"], progress_data), (CONFIG[\"failed_file\"], failed_data)]:\n",
    "        if os.path.exists(file):\n",
    "            try:\n",
    "                async with aiofiles.open(file, \"r\") as f:\n",
    "                    content = await f.read()\n",
    "                    if content.strip():\n",
    "                        data.update(json.loads(content))\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Error loading {file}: {e}\")\n",
    "    return progress_data, failed_data\n",
    "\n",
    "\n",
    "async def save_progress_data(progress_data: Dict[str, Any], failed_data: Dict[str, Any]) -> None:\n",
    "    \"\"\"Save progress and failed files data.\"\"\"\n",
    "    for file, data in [(CONFIG[\"progress_file\"], progress_data), (CONFIG[\"failed_file\"], failed_data)]:\n",
    "        try:\n",
    "            async with aiofiles.open(file, \"w\") as f:\n",
    "                await f.write(json.dumps(data, indent=2))\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error saving {file}: {e}\")\n",
    "\n",
    "\n",
    "async def process_files(num_files: Optional[int] = None) -> None:\n",
    "    \"\"\"Process files from configured directories.\"\"\"\n",
    "    if not CONFIG[\"api_key\"]:\n",
    "        logger.error(\"API key missing\")\n",
    "        return\n",
    "\n",
    "    file_paths = scan_directories()\n",
    "    progress_data, failed_data = await load_progress_data()\n",
    "    total_files = len(file_paths)  # Total files found\n",
    "    logger.info(f\"Total files found in directories: {total_files}\")\n",
    "\n",
    "    unprocessed_files = [f for f in file_paths if f not in progress_data[\"processed_files\"]]\n",
    "    logger.info(f\"Unprocessed files before processing: {len(unprocessed_files)}\")\n",
    "    files_to_process = unprocessed_files[:num_files] if num_files else unprocessed_files\n",
    "\n",
    "    if not files_to_process:\n",
    "        logger.info(\"No files to process\")\n",
    "        logger.info(f\"Remaining unprocessed files: {len(unprocessed_files)}\")\n",
    "        return\n",
    "\n",
    "    modified_files: List[str] = []\n",
    "    processed_count = 0\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        for file_path in files_to_process:\n",
    "            if num_files is not None and processed_count >= num_files:\n",
    "                break\n",
    "\n",
    "            refactored_code, usage = await refactor_code(session, file_path, CONFIG[\"prompt_template\"])\n",
    "            if not refactored_code:\n",
    "                failed_data[\"failed_files\"][file_path] = {\"timestamp\": time.time(), \"reason\": \"Refactoring failed\"}\n",
    "                await save_progress_data(progress_data, failed_data)\n",
    "                continue\n",
    "\n",
    "            file_cost = (usage.get(\"prompt_tokens\", 0) * INPUT_COST_PER_TOKEN +\n",
    "                         usage.get(\"completion_tokens\", 0) * OUTPUT_COST_PER_TOKEN)\n",
    "            total_cost = progress_data[\"total_cost\"] + file_cost\n",
    "\n",
    "            if CONFIG[\"cost_budget\"] > 0 and total_cost > CONFIG[\"cost_budget\"]:\n",
    "                logger.warning(f\"Cost budget exceeded: ${total_cost:.6f}\")\n",
    "                break\n",
    "\n",
    "            try:\n",
    "                async with aiofiles.open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                    original = await f.read()\n",
    "                async with aiofiles.open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                    await f.write(refactored_code)\n",
    "\n",
    "                if original != refactored_code:\n",
    "                    modified_files.append(file_path)\n",
    "\n",
    "                progress_data[\"processed_files\"].append(file_path)\n",
    "                progress_data[\"total_cost\"] = total_cost\n",
    "                processed_count += 1\n",
    "                logger.info(f\"Processed {file_path} - Cost: ${file_cost:.6f}\")\n",
    "\n",
    "                if CONFIG[\"auto_commit\"] and len(modified_files) >= CONFIG[\"auto_commit_interval\"]:\n",
    "                    await commit_files(modified_files, CONFIG[\"git_root_directory\"])\n",
    "                    modified_files = []\n",
    "\n",
    "                await save_progress_data(progress_data, failed_data)\n",
    "                await asyncio.sleep(CONFIG[\"request_delay\"])\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing {file_path}: {e}\")\n",
    "                failed_data[\"failed_files\"][file_path] = {\"timestamp\": time.time(), \"reason\": str(e)}\n",
    "                await save_progress_data(progress_data, failed_data)\n",
    "\n",
    "        if CONFIG[\"auto_commit\"] and modified_files:\n",
    "            await commit_files(modified_files, CONFIG[\"git_root_directory\"])\n",
    "\n",
    "    # Calculate and log remaining files\n",
    "    remaining_files = len(unprocessed_files) - processed_count\n",
    "    logger.info(f\"Processed {processed_count} files this run\")\n",
    "    logger.info(f\"Total files remaining to process: {remaining_files}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 07:20:55,645 - refactoring - INFO - Total files found in directories: 279\n",
      "2025-03-10 07:20:55,646 - refactoring - INFO - Unprocessed files before processing: 251\n",
      "2025-03-10 07:20:56,661 - refactoring - INFO - Processing C:\\Users\\harold.noble\\Desktop\\RIC\\app\\frontend\\src\\lib\\utils\\index.ts (attempt 1)\n",
      "2025-03-10 07:21:56,210 - refactoring - ERROR - API error 520 for C:\\Users\\harold.noble\\Desktop\\RIC\\app\\frontend\\src\\lib\\utils\\index.ts: <!DOCTYPE html>\n",
      "<!--[if lt IE 7]> <html class=\"no-js ie6 oldie\" lang=\"en-US\"> <![endif]-->\n",
      "<!--[if IE 7]>    <html class=\"no-js ie7 oldie\" lang=\"en-US\"> <![endif]-->\n",
      "<!--[if IE 8]>    <html class=\"no-\n",
      "2025-03-10 07:22:02,233 - refactoring - INFO - Processing C:\\Users\\harold.noble\\Desktop\\RIC\\app\\frontend\\src\\lib\\utils\\index.ts (attempt 2)\n",
      "2025-03-10 07:23:02,276 - refactoring - ERROR - API error 520 for C:\\Users\\harold.noble\\Desktop\\RIC\\app\\frontend\\src\\lib\\utils\\index.ts: <!DOCTYPE html>\n",
      "<!--[if lt IE 7]> <html class=\"no-js ie6 oldie\" lang=\"en-US\"> <![endif]-->\n",
      "<!--[if IE 7]>    <html class=\"no-js ie7 oldie\" lang=\"en-US\"> <![endif]-->\n",
      "<!--[if IE 8]>    <html class=\"no-\n",
      "2025-03-10 07:23:13,296 - refactoring - INFO - Processing C:\\Users\\harold.noble\\Desktop\\RIC\\app\\frontend\\src\\lib\\utils\\index.ts (attempt 3)\n",
      "2025-03-10 07:24:13,255 - refactoring - ERROR - API error 520 for C:\\Users\\harold.noble\\Desktop\\RIC\\app\\frontend\\src\\lib\\utils\\index.ts: <!DOCTYPE html>\n",
      "<!--[if lt IE 7]> <html class=\"no-js ie6 oldie\" lang=\"en-US\"> <![endif]-->\n",
      "<!--[if IE 7]>    <html class=\"no-js ie7 oldie\" lang=\"en-US\"> <![endif]-->\n",
      "<!--[if IE 8]>    <html class=\"no-\n",
      "2025-03-10 07:24:34,269 - refactoring - INFO - Processing C:\\Users\\harold.noble\\Desktop\\RIC\\app\\frontend\\src\\lib\\utils\\index.ts (attempt 4)\n",
      "2025-03-10 07:25:22,068 - refactoring - ERROR - API error 502 for C:\\Users\\harold.noble\\Desktop\\RIC\\app\\frontend\\src\\lib\\utils\\index.ts: <html>\n",
      "<head><title>502 Bad Gateway</title></head>\n",
      "<body>\n",
      "<center><h1>502 Bad Gateway</h1></center>\n",
      "<hr><center>cloudflare</center>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "2025-03-10 07:25:22,071 - refactoring - INFO - Processed 0 files this run\n",
      "2025-03-10 07:25:22,071 - refactoring - INFO - Total files remaining to process: 251\n"
     ]
    }
   ],
   "source": [
    "await process_files(num_files=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
