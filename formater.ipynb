{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import aiofiles\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Set, List, Optional, Dict, Any, Tuple\n",
    "import json\n",
    "\n",
    "PROCESSED_FILES_RECORD = \"processed_files.txt\"\n",
    "\n",
    "sources = {\n",
    "    \"OpenRouter\": {\n",
    "        \"base_url\": \"https://openrouter.ai/api/v1\",\n",
    "        \"model\": \"qwen/qwen-2.5-coder-32b-instruct:free\",\n",
    "        \"api_key\": \"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\"\n",
    "    },\n",
    "    \"Groq\": {\n",
    "        \"base_url\": \"https://api.groq.com/openai/v1/\",\n",
    "        \"model\": \"qwen-2.5-coder-32b\",\n",
    "        \"api_key\": \"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\"\n",
    "    },\n",
    "    \"Groq2\": {\n",
    "        \"base_url\": \"https://api.groq.com/openai/v1/\",\n",
    "        \"model\": \"qwen-2.5-coder-32b\",\n",
    "        \"api_key\": \"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\"\n",
    "    },\n",
    "    \"X.ai\": {\n",
    "        \"base_url\": \"https://api.x.ai/v1\",\n",
    "        \"model\": \"grok-2-latest\",\n",
    "        \"api_key\": \"xai-Lggu94vl22xIj5ThXFVu9nxbXjqYOqbTtLlxnibCypTkA5F8N4SvT0SDAYKIK8EkQCuVHv3tbfOPGiwt\"\n",
    "    },\n",
    "    \"Ollama\": {\n",
    "        \"base_url\": \"http://localhost:11434\",\n",
    "        \"model\": \"qwen2.5-coder\",\n",
    "        \"api_key\": None\n",
    "    }\n",
    "}\n",
    "\n",
    "# Set the selected source\n",
    "source = \"Groq\"\n",
    "CONFIG = {\n",
    "    \"base_url\": sources[source][\"base_url\"],\n",
    "    \"api_key\": sources[source][\"api_key\"],\n",
    "    \"model\": sources[source][\"model\"],\n",
    "    \"source_directories\": [r\"C:\\Users\\harold.noble\\Desktop\\RIC\\app\\frontend\\src\\lib\\components\\workspace\"],\n",
    "    \"skip_directories\": [\n",
    "        r\"C:\\Users\\harold.noble\\Desktop\\RIC\\app\\frontend\\src\\lib\\i18n\",\n",
    "    ],\n",
    "    \"pipeline_mode\": \"combined\",  # \"multiple\" \"single\" \"combined\"\n",
    "    \"selected_pass\": \"optimize\",\n",
    "    \"requests_per_minute\": 20,\n",
    "    \"concurrent_requests\": 3,\n",
    "    \"max_context_tokens\": 131072,\n",
    "    \"temperature\": 0.6,\n",
    "    \"top_p\": 0.95,\n",
    "    \"file_extensions\": [\".py\", \".ts\", \".svelte\"],\n",
    "    \"retry_sleep_seconds\": 30,\n",
    "    \"prompt_templates\": {\n",
    "        \"optimize\": (\n",
    "            \"Optimize the {file_type} code while preserving core functionality:\\n\"\n",
    "            \"- Remove all `i18n` references (e.g., `t()`, `$t`, `i18n.*`)\\n\"\n",
    "            \"- Think step by step about each change to ensure functionality is preserved\\n\"\n",
    "            \"- Simplify code and improve performance through careful analysis\\n\"\n",
    "            \"- Remove unused variables, imports, and dead code\\n\"\n",
    "            \"- Refactor repeated logic into reusable functions/components\\n\"\n",
    "            \"- Use descriptive, consistent naming (e.g., `calculateTotal` not `calc`)\\n\"\n",
    "            \"- Leverage {file_type}-specific features and best practices\\n\"\n",
    "            \"- Line length: 80-100 characters\\n\"\n",
    "            \"- Use early returns for clearer control flow\\n\"\n",
    "            \"- Follow CamelCase for variables/functions, PascalCase for classes/components\\n\"\n",
    "            \"- No empty lines between imports; one empty line before code\\n\"\n",
    "            \"- Preserve core logic and `onMount(() => {{`) in .svelte files\\n\"\n",
    "            \"- Be decisive in your optimizations, choosing the best approach rather than offering alternatives\\n\\n\"\n",
    "            \"Input code:\\n{content}\\n\\n\"\n",
    "            \"Return only the modified code without any explanations or additional text.\"\n",
    "        ),\n",
    "        \"comment_cleanup\": (\n",
    "            \"Process the {file_type} code while preserving functionality:\\n\"\n",
    "            \"- Remove all `i18n` references (e.g., `t()`, `$t`, `i18n.*`)\\n\"\n",
    "            \"- Remove all existing comments (e.g., `//`, `#`, `/* */`)\\n\"\n",
    "            \"- Add clear, concise, and informative documentation:\\n\"\n",
    "            \"  - For .py files: use `'''Purpose, parameters, returns'''` docstrings in every function and script section\\n\"\n",
    "            \"  - For .ts/.svelte files: use `/** Purpose, @param, @returns */` JSDoc comments for functions and components\\n\"\n",
    "            \"  - For HTML and Svelte markup: add comments in main areas to describe the structure and purpose of sections\\n\"\n",
    "            \"- Ensure every script block and main HTML area includes appropriate comments\\n\"\n",
    "            \"- Documentation should be precise and helpful without being verbose\\n\"\n",
    "            \"- Line length: 80-100 characters\\n\"\n",
    "            \"- Use early returns for clearer code paths\\n\"\n",
    "            \"- Follow CamelCase for variables/functions, PascalCase for classes/components\\n\"\n",
    "            \"- No empty lines between imports; one empty line before code\\n\"\n",
    "            \"- Preserve core logic and `onMount(() => {{`) in .svelte files\\n\"\n",
    "            \"- Be thorough and attentive to detail\\n\\n\"\n",
    "            \"Input code:\\n{content}\\n\\n\"\n",
    "            \"Return only the modified code without any explanations or additional text.\"\n",
    "        ),\n",
    "        \"verification\": (\n",
    "            \"Verify the modified {file_type} code with careful analysis:\\n\"\n",
    "            \"- Original: {original_content}\\n\"\n",
    "            \"- Modified: {modified_content}\\n\"\n",
    "            \"- Think step by step, comparing sections to ensure functionality preservation\\n\"\n",
    "            \"- Allow removal of: `i18n` references, unused code, empty import lines\\n\"\n",
    "            \"- Disallow changes to: core logic, `onMount(() => {{`) in .svelte files\\n\"\n",
    "            \"- Check that no functionality is missing or altered\\n\"\n",
    "            \"- Verify that all required imports remain intact\\n\"\n",
    "            \"- Ensure code standards are consistently applied\\n\"\n",
    "            \"- Be cautious about changes that might affect behavior\\n\"\n",
    "            \"- Return the modified code if valid; otherwise, return an empty string\\n\"\n",
    "            \"- Provide only the final verified code without any explanations or additional text\"\n",
    "        ),\n",
    "        \"combined\": (\n",
    "            \"Combine the following two tasks for the {file_type} code while preserving core functionality:\\n\"\n",
    "            \"1. Optimize the code by removing all `i18n` references, unused variables, imports, dead code, and by refactoring repeated logic. \"\n",
    "            \"Use descriptive naming, leverage {file_type}-specific best practices, and maintain clear control flow.\\n\"\n",
    "            \"2. Clean up comments by removing all existing comments and adding clear, concise, and informative documentation. \"\n",
    "            \"For .py files use docstrings; for .ts/.svelte files use JSDoc comments; and for markup add structured comments.\\n\\n\"\n",
    "            \"Remove code relating to: ldap, updating version, oauth, haptic, mobile.\"\n",
    "            \"Input code:\\n{content}\\n\\n\"\n",
    "            \"Return only the modified code without any explanations or additional text.\"\n",
    "        ),\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "def load_processed_files() -> Set[str]:\n",
    "    \"\"\"Load the list of already processed files.\"\"\"\n",
    "    if not os.path.exists(PROCESSED_FILES_RECORD):\n",
    "        return set()\n",
    "    with open(PROCESSED_FILES_RECORD, \"r\", encoding=\"utf-8\") as f:\n",
    "        return {line.strip() for line in f if line.strip()}\n",
    "\n",
    "\n",
    "def save_processed_files(file_paths: List[str]) -> None:\n",
    "    \"\"\"Add processed files to the record.\"\"\"\n",
    "    with open(PROCESSED_FILES_RECORD, \"a\", encoding=\"utf-8\") as f:\n",
    "        for fp in file_paths:\n",
    "            f.write(f\"{fp}\\n\")\n",
    "\n",
    "\n",
    "class RateLimiter:\n",
    "    def __init__(self, requests_per_minute: int):\n",
    "        self.interval = 60.0 / requests_per_minute\n",
    "        self.last_request_time = 0\n",
    "        self.lock = asyncio.Lock()\n",
    "\n",
    "    async def acquire(self):\n",
    "        async with self.lock:\n",
    "            current_time = asyncio.get_event_loop().time()\n",
    "            elapsed = current_time - self.last_request_time\n",
    "            if elapsed < self.interval:\n",
    "                await asyncio.sleep(self.interval - elapsed)\n",
    "            self.last_request_time = asyncio.get_event_loop().time()\n",
    "\n",
    "\n",
    "async def refactor_code(session: aiohttp.ClientSession, file_path: str, prompt: str, rate_limiter: RateLimiter, sem: asyncio.Semaphore) -> str:\n",
    "    \"\"\"Call the API with a given prompt and return the modified code. Handles both remote APIs and local Ollama.\"\"\"\n",
    "    if source == \"Ollama\":\n",
    "        try:\n",
    "            await rate_limiter.acquire()\n",
    "            async with sem:\n",
    "                loop = asyncio.get_event_loop()\n",
    "                response = await loop.run_in_executor(None, ollama.chat,\n",
    "                                                      model=CONFIG[\"model\"],\n",
    "                                                      messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                                                      options={\"temperature\": CONFIG[\"temperature\"], \"top_p\": CONFIG[\"top_p\"]}\n",
    "                                                      )\n",
    "                code = response[\"message\"][\"content\"].strip()\n",
    "                for marker in [\"```\" + Path(file_path).suffix[1:], \"```\"]:\n",
    "                    if code.startswith(marker) and code.endswith(\"```\"):\n",
    "                        code = \"\\n\".join(code.splitlines()[1:-1]).strip()\n",
    "                        break\n",
    "                return code or \"\"\n",
    "        except Exception as e:\n",
    "            print(f\"Ollama processing failed for {file_path}: {e}\")\n",
    "            return \"\"\n",
    "    else:\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {CONFIG['api_key']}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        payload = {\n",
    "            \"model\": CONFIG[\"model\"],\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "            \"temperature\": CONFIG[\"temperature\"],\n",
    "            \"top_p\": CONFIG[\"top_p\"],\n",
    "        }\n",
    "        for attempt in range(3):\n",
    "            try:\n",
    "                await rate_limiter.acquire()\n",
    "                async with sem:\n",
    "                    async with session.post(\n",
    "                        f\"{CONFIG['base_url']}/chat/completions\",\n",
    "                        json=payload,\n",
    "                        headers=headers,\n",
    "                        timeout=aiohttp.ClientTimeout(total=180)\n",
    "                    ) as response:\n",
    "                        if response.status == 429:\n",
    "                            error_text = await response.text()\n",
    "                            error_json = json.loads(error_text)\n",
    "                            if error_json.get(\"error\", {}).get(\"type\") == \"tokens\":\n",
    "                                retry_after = error_json[\"error\"].get(\"retry_after\", CONFIG[\"retry_sleep_seconds\"])\n",
    "                                print(f\"Rate limit reached for {file_path}. Retrying after {retry_after} seconds.\")\n",
    "                                await asyncio.sleep(retry_after)\n",
    "                                continue\n",
    "                            else:\n",
    "                                print(f\"Rate limit error {response.status} for {file_path}: {error_text}\")\n",
    "                                return \"\"\n",
    "\n",
    "                        if response.status == 413:  # Handle \"Request too large\" error\n",
    "                            error_text = await response.text()\n",
    "                            print(f\"Request too large for {file_path}: {error_text}\")\n",
    "                            return \"\"  # Skip retries immediately\n",
    "\n",
    "                        if response.status != 200:\n",
    "                            error_text = await response.text()\n",
    "                            print(f\"API error {response.status} for {file_path}: {error_text}\")\n",
    "                            continue\n",
    "\n",
    "                        result = await response.json()\n",
    "                        if \"choices\" not in result or not result[\"choices\"]:\n",
    "                            print(f\"Missing 'choices' in API response for {file_path}: {result}\")\n",
    "                            continue\n",
    "\n",
    "                        code = result[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "                        for marker in [\"```\" + Path(file_path).suffix[1:], \"```\"]:\n",
    "                            if code.startswith(marker) and code.endswith(\"```\"):\n",
    "                                code = \"\\n\".join(code.splitlines()[1:-1]).strip()\n",
    "                                break\n",
    "                        return code or \"\"\n",
    "            except Exception as e:\n",
    "                print(f\"Attempt {attempt + 1} failed for {file_path}: {e}\")\n",
    "                if attempt < 2:\n",
    "                    await asyncio.sleep(CONFIG[\"retry_sleep_seconds\"])\n",
    "        print(f\"All attempts failed for {file_path}\")\n",
    "        return \"\"\n",
    "\n",
    "async def process_single_file(session: aiohttp.ClientSession, file_path: str, rate_limiter: RateLimiter, sem: asyncio.Semaphore) -> bool:\n",
    "    \"\"\"\n",
    "    Process a single file based on the configured pipeline mode and return whether it was successfully processed and modified.\n",
    "    - \"multiple\": Run optimize, verification, comment cleanup, then final verification.\n",
    "    - \"combined\": Run one API call using a combined prompt.\n",
    "    - \"single\": Run only the selected pass (e.g., \"optimize\", \"comment_cleanup\", or \"verification\").\n",
    "    \"\"\"\n",
    "    file_ext = Path(file_path).suffix[1:]\n",
    "    try:\n",
    "        async with aiofiles.open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            original_content = await f.read()\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to read {file_path}: {e}\")\n",
    "        return False\n",
    "\n",
    "    modified_content = original_content\n",
    "    successfully_processed = False\n",
    "\n",
    "    mode = CONFIG[\"pipeline_mode\"]\n",
    "    if mode == \"multiple\":\n",
    "        optimize_prompt = CONFIG[\"prompt_templates\"][\"optimize\"].format(file_type=file_ext, content=modified_content)\n",
    "        optimized = await refactor_code(session, file_path, optimize_prompt, rate_limiter, sem)\n",
    "        if optimized:\n",
    "            modified_content = optimized\n",
    "\n",
    "        verify_prompt = CONFIG[\"prompt_templates\"][\"verification\"].format(file_type=file_ext, original_content=original_content, modified_content=modified_content)\n",
    "        verified_opt = await refactor_code(session, file_path, verify_prompt, rate_limiter, sem)\n",
    "        if verified_opt:\n",
    "            modified_content = verified_opt\n",
    "\n",
    "        cleanup_prompt = CONFIG[\"prompt_templates\"][\"comment_cleanup\"].format(file_type=file_ext, content=modified_content)\n",
    "        cleaned = await refactor_code(session, file_path, cleanup_prompt, rate_limiter, sem)\n",
    "        if cleaned:\n",
    "            modified_content = cleaned\n",
    "\n",
    "        final_verify_prompt = CONFIG[\"prompt_templates\"][\"verification\"].format(file_type=file_ext, original_content=original_content, modified_content=modified_content)\n",
    "        final_code = await refactor_code(session, file_path, final_verify_prompt, rate_limiter, sem)\n",
    "        if final_code:\n",
    "            modified_content = final_code\n",
    "\n",
    "    elif mode == \"combined\":\n",
    "        combined_prompt = CONFIG[\"prompt_templates\"][\"combined\"].format(file_type=file_ext, content=modified_content)\n",
    "        combined_result = await refactor_code(session, file_path, combined_prompt, rate_limiter, sem)\n",
    "        if combined_result:\n",
    "            modified_content = combined_result\n",
    "\n",
    "    elif mode == \"single\":\n",
    "        pass_name = CONFIG[\"selected_pass\"]\n",
    "        if pass_name not in CONFIG[\"prompt_templates\"]:\n",
    "            print(f\"Selected pass '{pass_name}' not found in prompt templates for {file_path}\")\n",
    "            return False\n",
    "        single_prompt = CONFIG[\"prompt_templates\"][pass_name].format(\n",
    "            file_type=file_ext, content=modified_content,\n",
    "            original_content=original_content, modified_content=modified_content\n",
    "        )\n",
    "        single_result = await refactor_code(session, file_path, single_prompt, rate_limiter, sem)\n",
    "        if single_result:\n",
    "            modified_content = single_result\n",
    "\n",
    "    # Only consider it successfully processed if the content has changed\n",
    "    if modified_content != original_content:\n",
    "        try:\n",
    "            async with aiofiles.open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                await f.write(modified_content)\n",
    "            print(f\"Processed: {file_path}\")\n",
    "            successfully_processed = True\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to write {file_path}: {e}\")\n",
    "            successfully_processed = False\n",
    "    else:\n",
    "        print(f\"No changes for: {file_path}\")\n",
    "        successfully_processed = False\n",
    "\n",
    "    return successfully_processed\n",
    "\n",
    "\n",
    "async def main(max_files_to_process: Optional[int] = None):\n",
    "    if not os.path.exists(PROCESSED_FILES_RECORD):\n",
    "        open(PROCESSED_FILES_RECORD, \"w\", encoding=\"utf-8\").close()\n",
    "\n",
    "    file_paths = scan_directories()\n",
    "    if max_files_to_process is not None:\n",
    "        file_paths = file_paths[:max_files_to_process]\n",
    "\n",
    "    if not file_paths:\n",
    "        print(\"No new files to process. Exiting.\")\n",
    "        return\n",
    "\n",
    "    backup_dir = backup_files(file_paths)\n",
    "    rate_limiter = RateLimiter(CONFIG[\"requests_per_minute\"])\n",
    "    sem = asyncio.Semaphore(CONFIG[\"concurrent_requests\"])\n",
    "\n",
    "    connector = aiohttp.TCPConnector(limit=CONFIG[\"concurrent_requests\"])\n",
    "    async with aiohttp.ClientSession(connector=connector) as session:\n",
    "        tasks = [process_single_file(session, fp, rate_limiter, sem) for fp in file_paths]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        processed_files = [fp for fp, success in zip(file_paths, results) if success]\n",
    "\n",
    "        save_processed_files(processed_files)\n",
    "        print(f\"Added {len(processed_files)} files to processed files record.\")\n",
    "\n",
    "    if backup_dir and os.path.exists(backup_dir):\n",
    "        shutil.rmtree(backup_dir)\n",
    "        print(f\"Removed backup directory {backup_dir}\")\n",
    "\n",
    "    print(f\"Processing complete. {len(processed_files)} files processed.\")\n",
    "\n",
    "\n",
    "def should_skip_file(file_path: Path, skip_dirs: List[Path]) -> bool:\n",
    "    \"\"\"Check if a file should be skipped based on skip directories.\"\"\"\n",
    "    file_path_str = str(file_path.resolve())\n",
    "    for skip_dir in skip_dirs:\n",
    "        skip_dir_str = str(skip_dir)\n",
    "        if file_path_str.startswith(skip_dir_str) and (\n",
    "            len(file_path_str) == len(skip_dir_str) or file_path_str[len(skip_dir_str)] == os.path.sep\n",
    "        ):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def scan_directories() -> List[str]:\n",
    "    \"\"\"Scan source directories and return new file paths to process.\"\"\"\n",
    "    processed_files = load_processed_files()\n",
    "    file_paths = []\n",
    "    skip_dirs = [Path(d).resolve() for d in CONFIG[\"skip_directories\"]]\n",
    "\n",
    "    for directory in CONFIG[\"source_directories\"]:\n",
    "        dir_path = Path(directory).resolve()\n",
    "        if not dir_path.is_dir():\n",
    "            print(f\"Directory not found: {directory}\")\n",
    "            continue\n",
    "        for ext in CONFIG[\"file_extensions\"]:\n",
    "            for file_path in dir_path.glob(f\"**/*{ext}\"):\n",
    "                file_path = file_path.resolve()\n",
    "                if should_skip_file(file_path, skip_dirs) or str(file_path) in processed_files:\n",
    "                    continue\n",
    "                file_paths.append(str(file_path))\n",
    "    print(f\"Found {len(file_paths)} new files to process\")\n",
    "    return file_paths\n",
    "\n",
    "\n",
    "def backup_files(file_paths: List[str]) -> str:\n",
    "    \"\"\"Backup files before processing.\"\"\"\n",
    "    if not file_paths:\n",
    "        print(\"No files to backup\")\n",
    "        return \"\"\n",
    "    backup_dir = f\"backup_{int(time.time())}\"\n",
    "    os.makedirs(backup_dir, exist_ok=True)\n",
    "    for fp in file_paths:\n",
    "        shutil.copy(fp, os.path.join(backup_dir, os.path.basename(fp)))\n",
    "    print(f\"Backed up {len(file_paths)} files to {backup_dir}\")\n",
    "    return backup_dir\n",
    "\n",
    "\n",
    "async def main(max_files_to_process: Optional[int] = None):\n",
    "    if not os.path.exists(PROCESSED_FILES_RECORD):\n",
    "        open(PROCESSED_FILES_RECORD, \"w\", encoding=\"utf-8\").close()\n",
    "\n",
    "    file_paths = scan_directories()\n",
    "    if max_files_to_process is not None:\n",
    "        file_paths = file_paths[:max_files_to_process]\n",
    "\n",
    "    if not file_paths:\n",
    "        print(\"No new files to process. Exiting.\")\n",
    "        return\n",
    "\n",
    "    backup_dir = backup_files(file_paths)\n",
    "    rate_limiter = RateLimiter(CONFIG[\"requests_per_minute\"])\n",
    "    sem = asyncio.Semaphore(CONFIG[\"concurrent_requests\"])\n",
    "\n",
    "    connector = aiohttp.TCPConnector(limit=CONFIG[\"concurrent_requests\"])\n",
    "    async with aiohttp.ClientSession(connector=connector) as session:\n",
    "        tasks = [process_single_file(session, fp, rate_limiter, sem) for fp in file_paths]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        processed_files = [fp for fp, success in zip(file_paths, results) if success]\n",
    "\n",
    "        save_processed_files(processed_files)\n",
    "        print(f\"Added {len(processed_files)} files to processed files record.\")\n",
    "\n",
    "    if backup_dir and os.path.exists(backup_dir):\n",
    "        shutil.rmtree(backup_dir)\n",
    "        print(f\"Removed backup directory {backup_dir}\")\n",
    "\n",
    "    print(f\"Processing complete. {len(processed_files)} files processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26 new files to process\n",
      "Backed up 10 files to backup_1741893441\n",
      "Processed: C:\\Users\\harold.noble\\Desktop\\RIC\\app\\frontend\\src\\lib\\components\\workspace\\Knowledge.svelte\n",
      "Processed: C:\\Users\\harold.noble\\Desktop\\RIC\\app\\frontend\\src\\lib\\components\\workspace\\Prompts.svelte\n",
      "Processed: C:\\Users\\harold.noble\\Desktop\\RIC\\app\\frontend\\src\\lib\\components\\workspace\\Knowledge\\ItemMenu.svelte\n",
      "Processed: C:\\Users\\harold.noble\\Desktop\\RIC\\app\\frontend\\src\\lib\\components\\workspace\\Tools.svelte\n",
      "Processed: C:\\Users\\harold.noble\\Desktop\\RIC\\app\\frontend\\src\\lib\\components\\workspace\\common\\AccessControlModal.svelte\n",
      "Rate limit reached for C:\\Users\\harold.noble\\Desktop\\RIC\\app\\frontend\\src\\lib\\components\\workspace\\Models.svelte. Retrying after 30 seconds.\n",
      "Rate limit reached for C:\\Users\\harold.noble\\Desktop\\RIC\\app\\frontend\\src\\lib\\components\\workspace\\common\\AccessControl.svelte. Retrying after 30 seconds.\n",
      "Processed: C:\\Users\\harold.noble\\Desktop\\RIC\\app\\frontend\\src\\lib\\components\\workspace\\common\\ManifestModal.svelte\n",
      "Rate limit reached for C:\\Users\\harold.noble\\Desktop\\RIC\\app\\frontend\\src\\lib\\components\\workspace\\Knowledge\\CreateKnowledgeBase.svelte. Retrying after 30 seconds.\n",
      "Processed: C:\\Users\\harold.noble\\Desktop\\RIC\\app\\frontend\\src\\lib\\components\\workspace\\common\\ValvesModal.svelte\n",
      "Rate limit reached for C:\\Users\\harold.noble\\Desktop\\RIC\\app\\frontend\\src\\lib\\components\\workspace\\Models.svelte. Retrying after 30 seconds.\n",
      "Rate limit reached for C:\\Users\\harold.noble\\Desktop\\RIC\\app\\frontend\\src\\lib\\components\\workspace\\common\\AccessControl.svelte. Retrying after 30 seconds.\n",
      "Rate limit reached for C:\\Users\\harold.noble\\Desktop\\RIC\\app\\frontend\\src\\lib\\components\\workspace\\Knowledge\\CreateKnowledgeBase.svelte. Retrying after 30 seconds.\n",
      "Rate limit reached for C:\\Users\\harold.noble\\Desktop\\RIC\\app\\frontend\\src\\lib\\components\\workspace\\Models.svelte. Retrying after 30 seconds.\n",
      "Processed: C:\\Users\\harold.noble\\Desktop\\RIC\\app\\frontend\\src\\lib\\components\\workspace\\common\\AccessControl.svelte\n",
      "Processed: C:\\Users\\harold.noble\\Desktop\\RIC\\app\\frontend\\src\\lib\\components\\workspace\\Knowledge\\CreateKnowledgeBase.svelte\n",
      "All attempts failed for C:\\Users\\harold.noble\\Desktop\\RIC\\app\\frontend\\src\\lib\\components\\workspace\\Models.svelte\n",
      "No changes for: C:\\Users\\harold.noble\\Desktop\\RIC\\app\\frontend\\src\\lib\\components\\workspace\\Models.svelte\n",
      "Added 9 files to processed files record.\n",
      "Removed backup directory backup_1741893441\n",
      "Processing complete. 9 files processed.\n"
     ]
    }
   ],
   "source": [
    "await main(max_files_to_process=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10):  # Outer loop runs 10 times\n",
    "    for _ in range(3):  # Inner loop runs 3 times\n",
    "        await main(max_files_to_process=5)\n",
    "        await asyncio.sleep(60 * 2)  # Sleep for 2 minutes between inner loop iterations\n",
    "    await asyncio.sleep(60 * 5)  # Sleep for 5 minutes between outer loop iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
