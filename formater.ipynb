{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import shutil\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import aiofiles\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Set, List, Optional, Dict, Any, Tuple\n",
    "import json\n",
    "import re\n",
    "\n",
    "PROCESSED_FILES_RECORD = \"processed_files.txt\"\n",
    "\n",
    "sources = {\n",
    "    \"OpenRouter\": {\n",
    "        \"base_url\": \"https://openrouter.ai/api/v1\",\n",
    "        \"model\": \"qwen/qwen-2.5-coder-32b-instruct:free\",\n",
    "        \"api_key\": \"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\"\n",
    "    },\n",
    "    \"Groq\": {\n",
    "        \"base_url\": \"https://api.groq.com/openai/v1/\",\n",
    "        \"model\": \"qwen-2.5-coder-32b\",\n",
    "        \"api_key\": \"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\"\n",
    "    },\n",
    "    \"Groq2\": {\n",
    "        \"base_url\": \"https://api.groq.com/openai/v1/\",\n",
    "        \"model\": \"qwen-2.5-coder-32b\",\n",
    "        \"api_key\": \"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\"\n",
    "    },\n",
    "    \"X.ai\": {\n",
    "        \"base_url\": \"https://api.x.ai/v1\",\n",
    "        \"model\": \"grok-2-latest\",\n",
    "        \"api_key\": \"xai-Lggu94vl22xIj5ThXFVu9nxbXjqYOqbTtLlxnibCypTkA5F8N4SvT0SDAYKIK8EkQCuVHv3tbfOPGiwt\"\n",
    "    },\n",
    "    \"Ollama\": {\n",
    "        \"base_url\": \"http://localhost:11434\",\n",
    "        \"model\": \"qwen2.5-coder\",\n",
    "        \"api_key\": None\n",
    "    }\n",
    "}\n",
    "\n",
    "# Set the selected source\n",
    "source = \"X.ai\"\n",
    "\n",
    "# Base configuration\n",
    "BASE_CONFIG = {\n",
    "    \"source_directories\": [r\"C:\\Users\\harold.noble\\Desktop\\RIC\\app\"],\n",
    "    \"skip_directories\": [],\n",
    "    \"selected_pass\": \"adjust_comments\",\n",
    "    \"requests_per_minute\": 5,\n",
    "    \"concurrent_requests\": 3,\n",
    "    \"max_context_tokens\": 6000,\n",
    "    \"skip_long_files\": False,\n",
    "    \"temperature\": 0.6,\n",
    "    \"top_p\": 0.95,\n",
    "    \"file_extensions\": [\".py\", \".ts\", \".svelte\"],\n",
    "    \"retry_sleep_seconds\": 30,\n",
    "    \"search_terms\": [],\n",
    "    \"prompt_templates\": {\n",
    "        \"optimize\": (\n",
    "            \"Optimize the {file_type} code while preserving core functionality:\\n\"\n",
    "            \"- Remove all i18n references (e.g., t(), $t, i18n.*) unless tied to core logic\\n\"\n",
    "            \"- Eliminate unused variables, imports, and dead code after verifying no external dependencies\\n\"\n",
    "            \"- Refactor repeated logic into reusable functions or components with descriptive names (e.g., calculateTotal, not calc)\\n\"\n",
    "            \"- Simplify code by:\\n\"\n",
    "            \"  - Using early returns to reduce nesting\\n\"\n",
    "            \"  - Replacing complex conditionals with clearer alternatives where possible\\n\"\n",
    "            \"- Improve performance by minimizing loops and redundant operations\\n\"\n",
    "            \"- Use {file_type}-specific best practices (e.g., async/await in .ts, reactive statements in .svelte)\\n\"\n",
    "            \"- Naming: variables/functions in camelCase, classes/components in PascalCase\\n\"\n",
    "            \"- Keep lines between 80-100 characters; break logically if longer\\n\"\n",
    "            \"- No empty lines between imports; one empty line before code\\n\"\n",
    "            \"- Preserve core logic, including onMount(() => {{) in .svelte files\\n\"\n",
    "            \"- Define core functionality as: primary operations the script performs, excluding optional features\\n\"\n",
    "            \"- Be decisive: apply the most effective optimization without alternatives\\n\"\n",
    "            \"Input code:\\n{content}\\n\\n\"\n",
    "            \"Return only the modified code without explanations or additional text.\"\n",
    "        ),\n",
    "        \"comment_cleanup\": (\n",
    "            \"Process the {file_type} code while preserving all functionality:\\n\"\n",
    "            \"- Remove all existing comments (e.g., //, #, /* */)\\n\"\n",
    "            \"- Add precise documentation as follows:\\n\"\n",
    "            \"  - For .py files: add a triple-quoted docstring ('''') to every function and top-level script block, including:\\n\"\n",
    "            \"    - Purpose: one sentence describing what it does\\n\"\n",
    "            \"    - Parameters: list each parameter with type and purpose\\n\"\n",
    "            \"    - Returns: describe the return value and type\\n\"\n",
    "            \"  - For .ts/.svelte files: add JSDoc comments (/** */) above every function and component, including:\\n\"\n",
    "            \"    - Purpose: one sentence describing what it does\\n\"\n",
    "            \"    - @param {{type}} name - purpose of each parameter\\n\"\n",
    "            \"    - @returns {{type}} - description of return value\\n\"\n",
    "            \"  - For HTML/Svelte markup: add <!-- Section: purpose --> comments to separate and describe major structural blocks (e.g., header, main content)\\n\"\n",
    "            \"- Keep comments concise: max 2 lines unless complex logic requires more\\n\"\n",
    "            \"- For complex logic, add brief inline comments (e.g., // Calculate total score)\\n\"\n",
    "            \"- No empty lines between imports; one empty line before code begins\\n\"\n",
    "            \"- Preserve core logic, including onMount(() => {{) in .svelte files\\n\"\n",
    "            \"Input code:\\n{content}\\n\\n\"\n",
    "            \"Return only the modified code without explanations or additional text.\"\n",
    "        ),\n",
    "        \"combined\": (\n",
    "            \"Combine the following two tasks for the {file_type} code while preserving core functionality:\\n\"\n",
    "            \"1. Optimize the code by removing all i18n references, unused variables, imports, dead code, and by refactoring repeated logic. \"\n",
    "            \"Apply general optimizations such as eliminating unnecessary if statements when only one option exists, \"\n",
    "            \"simplifying conditionals, and reducing redundant operations. \"\n",
    "            \"Use descriptive naming, leverage {file_type}-specific best practices, and maintain clear control flow. \"\n",
    "            \"Remove code relating to: ldap, updating version, oauth, haptic, mobile, channels, googledrive, onedrive, CallOverlay, transparentBackground, backgroundImageUrl.\\n\"\n",
    "            \"2. Clean up comments by removing all existing comments and adding clear, concise, and informative documentation. \"\n",
    "            \"Add comments to every function: for .py files, use docstrings with purpose, parameters, and returns; \"\n",
    "            \"for .ts/.svelte files, use JSDoc comments (purpose, @param, @returns). \"\n",
    "            \"For HTML/markup, add structured comments to describe the layout and purpose of every section and function.\\n\\n\"\n",
    "            \"Input code:\\n{content}\\n\\n\"\n",
    "            \"Return only the modified code without any explanations or additional text.\"\n",
    "        ),\n",
    "        \"python_combined\": (\n",
    "            \"Process the following Python code by combining these two tasks while preserving core functionality:\\n\"\n",
    "            \"1. Optimize the code by removing unused variables, imports, dead code, and refactoring repeated logic. \"\n",
    "            \"Apply Python-specific optimizations such as using list comprehensions where appropriate, simplifying conditionals, \"\n",
    "            \"eliminating unnecessary if statements with single options, and reducing redundant operations. \"\n",
    "            \"Use PEP 8-compliant naming, leverage Python best practices (e.g., context managers, built-in functions), and ensure clear control flow. \"\n",
    "            \"Ensure no blank lines between import statements and remove code related to: ldap, updating version, oauth, haptic, mobile, channels, \"\n",
    "            \"googledrive, onedrive, CallOverlay, transparentBackground, backgroundImageUrl.\\n\"\n",
    "            \"2. Clean up comments by removing all existing comments and adding clear, concise, and informative documentation. \"\n",
    "            \"Add docstrings to every function with purpose, parameters, and return values following Python docstring conventions (e.g., Google or NumPy style). \"\n",
    "            \"Include brief inline comments only where complex logic requires clarification.\\n\\n\"\n",
    "            \"Input code:\\n{content}\\n\\n\"\n",
    "            \"Return only the modified code without any explanations or additional text.\"\n",
    "        ),\n",
    "        \"adjust_comments\": (\n",
    "            \"Adjust comments in the {file_type} code while preserving all functionality:\\n\"\n",
    "            \"- Remove all existing comments\\n\"\n",
    "            \"- Add concise, meaningful single-line comments (unless a docstring) as follows:\\n\"\n",
    "            \"  - For .py files: add a triple-quoted docstring ('''') to every function describing its purpose in one sentence\\n\"\n",
    "            \"    - Add single-line comments (e.g., # Purpose) before significant code blocks\\n\"\n",
    "            \"  - For .ts/.svelte files: add single-line JSDoc-style comments (// Purpose) above functions\\n\"\n",
    "            \"    - Use // @param name - purpose and // @returns - purpose where applicable\\n\"\n",
    "            \"  - For HTML/Svelte markup: add single-line <!-- Purpose --> comments before major sections\\n\"\n",
    "            \"- Keep comments on one line, max 80 characters, unless it's a docstring\\n\"\n",
    "            \"- Focus comments on explaining 'why' rather than 'what', unless the logic is complex\\n\"\n",
    "            \"- Do not modify any functional code, only adjust comments\\n\"\n",
    "            \"Input code:\\n{content}\\n\\n\"\n",
    "            \"Return only the modified code without explanations or additional text.\"\n",
    "        ),\n",
    "    }\n",
    "}\n",
    "\n",
    "# Set up CONFIGS based on source\n",
    "if source == \"Groq\":\n",
    "    CONFIGS = [\n",
    "        {**BASE_CONFIG, \"base_url\": sources[\"Groq\"][\"base_url\"], \"api_key\": sources[\"Groq\"][\"api_key\"], \"model\": sources[\"Groq\"][\"model\"]},\n",
    "        {**BASE_CONFIG, \"base_url\": sources[\"Groq2\"][\"base_url\"], \"api_key\": sources[\"Groq2\"][\"api_key\"], \"model\": sources[\"Groq2\"][\"model\"]}\n",
    "    ]\n",
    "else:\n",
    "    CONFIGS = [{**BASE_CONFIG, \"base_url\": sources[source][\"base_url\"], \"api_key\": sources[source][\"api_key\"], \"model\": sources[source][\"model\"]}]\n",
    "\n",
    "\n",
    "def load_processed_files() -> Set[str]:\n",
    "    \"\"\"Load previously processed file paths.\"\"\"\n",
    "    return set(line.strip() for line in open(PROCESSED_FILES_RECORD, \"r\", encoding=\"utf-8\").readlines()) if os.path.exists(PROCESSED_FILES_RECORD) else set()\n",
    "\n",
    "def save_processed_files(file_paths: List[str]) -> None:\n",
    "    \"\"\"Append newly processed file paths to record.\"\"\"\n",
    "    with open(PROCESSED_FILES_RECORD, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.writelines(f\"{fp}\\n\" for fp in file_paths)\n",
    "\n",
    "\n",
    "class RateLimiter:\n",
    "    def __init__(self, requests_per_minute: int):\n",
    "        self.interval = 60.0 / requests_per_minute\n",
    "        self.last_request_time = time.time()\n",
    "        self.lock = asyncio.Lock()\n",
    "\n",
    "    async def acquire(self):\n",
    "        async with self.lock:\n",
    "            current_time = time.time()\n",
    "            sleep_time = self.interval - (current_time - self.last_request_time)\n",
    "            if sleep_time > 0:\n",
    "                await asyncio.sleep(sleep_time)\n",
    "            self.last_request_time = time.time()\n",
    "\n",
    "\n",
    "async def refactor_code(session: aiohttp.ClientSession, file_path: str, prompt: str, rate_limiter: RateLimiter, sem: asyncio.Semaphore, config: Dict) -> str:\n",
    "    \"\"\"Refactor code using API with improved error handling.\"\"\"\n",
    "    headers = {\"Authorization\": f\"Bearer {config['api_key']}\", \"Content-Type\": \"application/json\"}\n",
    "    payload = {\n",
    "        \"model\": config[\"model\"],\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"temperature\": config[\"temperature\"],\n",
    "        \"top_p\": config[\"top_p\"],\n",
    "    }\n",
    "\n",
    "    async with sem:  # Only use semaphore as context manager\n",
    "        await rate_limiter.acquire()  # Call acquire directly\n",
    "        for attempt in range(3):\n",
    "            try:\n",
    "                async with session.post(\n",
    "                    f\"{config['base_url']}/chat/completions\",\n",
    "                    json=payload,\n",
    "                    headers=headers,\n",
    "                    timeout=aiohttp.ClientTimeout(total=180)\n",
    "                ) as response:\n",
    "                    if response.status != 200:\n",
    "                        if response.status == 429:\n",
    "                            await asyncio.sleep(config[\"retry_sleep_seconds\"])\n",
    "                            continue\n",
    "                        print(f\"API error {response.status} for {file_path}: {await response.text()}\")\n",
    "                        return \"\"\n",
    "\n",
    "                    result = await response.json()\n",
    "                    code = result.get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\").strip()\n",
    "                    if not code:\n",
    "                        print(f\"Empty response for {file_path}\")\n",
    "                        return \"\"\n",
    "\n",
    "                    file_ext = Path(file_path).suffix[1:]\n",
    "                    markers = [f\"```{file_ext}\", \"```\"]\n",
    "                    if code.startswith(markers[0]) and code.endswith(markers[1]):\n",
    "                        code = code[len(markers[0]):-len(markers[1])].strip()\n",
    "                    return code\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Attempt {attempt + 1} failed for {file_path}: {e}\")\n",
    "                if attempt < 2:\n",
    "                    await asyncio.sleep(config[\"retry_sleep_seconds\"])\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def split_into_chunks(content: str, max_tokens: int) -> List[str]:\n",
    "    \"\"\"Split code into chunks based on token estimate (approx 4 chars per token).\"\"\"\n",
    "    lines = content.splitlines()\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "    token_limit = max_tokens * 4  # Rough estimate: 4 characters per token\n",
    "\n",
    "    for line in lines:\n",
    "        line_length = len(line)\n",
    "        if current_length + line_length > token_limit and current_chunk:\n",
    "            chunks.append(\"\\n\".join(current_chunk))\n",
    "            current_chunk = [line]\n",
    "            current_length = line_length\n",
    "        else:\n",
    "            current_chunk.append(line)\n",
    "            current_length += line_length + 1  # +1 for newline\n",
    "    if current_chunk:\n",
    "        chunks.append(\"\\n\".join(current_chunk))\n",
    "    return chunks\n",
    "\n",
    "\n",
    "async def process_single_file(session: aiohttp.ClientSession, file_path: str, rate_limiter: RateLimiter, sem: asyncio.Semaphore, config: Dict) -> bool:\n",
    "    \"\"\"Process a single file, splitting into chunks if necessary.\"\"\"\n",
    "    file_ext = Path(file_path).suffix[1:]\n",
    "    try:\n",
    "        async with aiofiles.open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            content = await f.read()\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to read {file_path}: {e}\")\n",
    "        return False\n",
    "\n",
    "    # Split into chunks if content is too long\n",
    "    chunks = split_into_chunks(content, config[\"max_context_tokens\"])\n",
    "    modified_chunks = []\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        if config[\"skip_long_files\"] and (len(chunk) // 4) > config[\"max_context_tokens\"]:\n",
    "            print(f\"Skipping chunk {i+1} of {file_path} (too long)\")\n",
    "            modified_chunks.append(chunk)  # Keep original chunk if too long\n",
    "            continue\n",
    "\n",
    "        prompt = config[\"prompt_templates\"].get(config[\"selected_pass\"], \"\").format(file_type=file_ext, content=chunk)\n",
    "        if not prompt:\n",
    "            print(f\"Invalid pass for chunk {i+1} of {file_path}\")\n",
    "            modified_chunks.append(chunk)\n",
    "            continue\n",
    "\n",
    "        modified_content = await refactor_code(session, file_path, prompt, rate_limiter, sem, config)\n",
    "        if not modified_content:\n",
    "            modified_chunks.append(chunk)  # Keep original if refactoring fails\n",
    "        else:\n",
    "            modified_chunks.append(modified_content)\n",
    "\n",
    "    modified_content = \"\\n\".join(modified_chunks)\n",
    "    if modified_content == content:\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        async with aiofiles.open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            await f.write(modified_content)\n",
    "        print(f\"Processed: {file_path}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to write {file_path}: {e}\")\n",
    "        return False\n",
    "    \n",
    "def should_skip_file(file_path: Path, skip_dirs: List[Path]) -> bool:\n",
    "    \"\"\"Check if file should be skipped based on directories.\"\"\"\n",
    "    file_path_str = str(file_path)\n",
    "    return any(file_path_str.startswith(str(skip_dir)) for skip_dir in skip_dirs)\n",
    "\n",
    "def scan_directories(config: Dict) -> List[str]:\n",
    "    \"\"\"Scan directories for files containing search terms.\"\"\"\n",
    "    processed_files = load_processed_files()\n",
    "    file_paths = []\n",
    "    skip_dirs = [Path(d).resolve() for d in config[\"skip_directories\"]]\n",
    "\n",
    "    for directory in config[\"source_directories\"]:\n",
    "        dir_path = Path(directory).resolve()\n",
    "        if not dir_path.is_dir():\n",
    "            continue\n",
    "        for ext in config[\"file_extensions\"]:\n",
    "            for file_path in dir_path.glob(f\"**/*{ext}\"):\n",
    "                file_path_str = str(file_path.resolve())\n",
    "                if file_path_str in processed_files or should_skip_file(file_path, skip_dirs):\n",
    "                    continue\n",
    "                file_paths.append(file_path_str)\n",
    "\n",
    "    print(f\"Found {len(file_paths)} potential files\")\n",
    "    return file_paths\n",
    "\n",
    "def backup_files(file_paths: List[str]) -> str:\n",
    "    \"\"\"Create backup of files.\"\"\"\n",
    "    if not file_paths:\n",
    "        return \"\"\n",
    "    backup_dir = f\"backup_{int(time.time())}\"\n",
    "    os.makedirs(backup_dir, exist_ok=True)\n",
    "    for fp in file_paths:\n",
    "        shutil.copy(fp, os.path.join(backup_dir, os.path.basename(fp)))\n",
    "    return backup_dir\n",
    "\n",
    "async def process_file_batch(session: aiohttp.ClientSession, file_paths: List[str], config: Dict, rate_limiter: RateLimiter, sem: asyncio.Semaphore) -> List[bool]:\n",
    "    \"\"\"Process a batch of files.\"\"\"\n",
    "    return await asyncio.gather(*[process_single_file(session, fp, rate_limiter, sem, config) for fp in file_paths])\n",
    "\n",
    "\n",
    "async def main(search_terms: List[str] = None, max_files_to_process: Optional[int] = None):\n",
    "    \"\"\"Main function with search term filtering.\"\"\"\n",
    "    # Update config with search terms\n",
    "    for config in CONFIGS:\n",
    "        config[\"search_terms\"] = search_terms or []\n",
    "\n",
    "    if not os.path.exists(PROCESSED_FILES_RECORD):\n",
    "        open(PROCESSED_FILES_RECORD, \"w\", encoding=\"utf-8\").close()\n",
    "\n",
    "    # Scan all files first\n",
    "    all_file_paths = scan_directories(CONFIGS[0])\n",
    "\n",
    "    # Filter files containing search terms\n",
    "    matching_files = []\n",
    "    for file_path in all_file_paths:\n",
    "        try:\n",
    "            async with aiofiles.open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                content = await f.read()\n",
    "            pattern = '|'.join(rf\"(?:{re.escape(term)})\" for term in config[\"search_terms\"])\n",
    "            if re.search(pattern, content, re.IGNORECASE):\n",
    "                matching_files.append(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file_path}: {e}\")\n",
    "\n",
    "    print(f\"Found {len(matching_files)} files containing search terms: {search_terms}\")\n",
    "\n",
    "    # Apply max_files_to_process limit after filtering\n",
    "    file_paths = matching_files\n",
    "    if max_files_to_process is not None:\n",
    "        file_paths = file_paths[:max_files_to_process]\n",
    "\n",
    "    if not file_paths:\n",
    "        print(\"No matching files found.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Processing {len(file_paths)} files\")\n",
    "    backup_dir = backup_files(file_paths)\n",
    "\n",
    "    file_batches = [file_paths] if source != \"Groq\" or len(CONFIGS) == 1 else [file_paths[:len(file_paths)//2], file_paths[len(file_paths)//2:]]\n",
    "\n",
    "    rate_limiters = [RateLimiter(config[\"requests_per_minute\"]) for config in CONFIGS]\n",
    "    semaphores = [asyncio.Semaphore(config[\"concurrent_requests\"]) for config in CONFIGS]\n",
    "\n",
    "    async with aiohttp.ClientSession(connector=aiohttp.TCPConnector(limit=sum(c[\"concurrent_requests\"] for c in CONFIGS))) as session:\n",
    "        all_results = []\n",
    "        for config, files, rate_limiter, sem in zip(CONFIGS, file_batches, rate_limiters, semaphores):\n",
    "            if files:\n",
    "                # Remove the search term check from process_single_file since we already filtered\n",
    "                results = await process_file_batch(session, files, config, rate_limiter, sem)\n",
    "                all_results.extend(results)\n",
    "\n",
    "        processed_files = [fp for fp, success in zip(file_paths, all_results) if success]\n",
    "        save_processed_files(processed_files)\n",
    "        print(f\"Processed {len(processed_files)} files\")\n",
    "\n",
    "    if backup_dir and os.path.exists(backup_dir):\n",
    "        shutil.rmtree(backup_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 427 potential files\n",
      "Found 8 files containing search terms: ['mobile']\n",
      "Processing 5 files\n",
      "Processed: C:\\Users\\harold.noble\\Desktop\\RIC\\app\\frontend\\src\\lib\\stores\\index.ts\n",
      "Processed: C:\\Users\\harold.noble\\Desktop\\RIC\\app\\frontend\\src\\routes\\+layout.svelte\n",
      "Processed: C:\\Users\\harold.noble\\Desktop\\RIC\\app\\frontend\\src\\lib\\components\\chat\\MessageInput.svelte\n",
      "Processed: C:\\Users\\harold.noble\\Desktop\\RIC\\app\\frontend\\src\\lib\\components\\common\\Banner.svelte\n",
      "Processed: C:\\Users\\harold.noble\\Desktop\\RIC\\app\\frontend\\src\\lib\\components\\chat\\Chat.svelte\n",
      "Processed 5 files\n"
     ]
    }
   ],
   "source": [
    "await main(search_terms=[\"mobile\"], max_files_to_process=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
